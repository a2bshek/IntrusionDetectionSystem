{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction\n",
    "\n",
    "# buffer_overflow. to -1\n",
    "# normal. to 0\n",
    "# loadmodule. to 1\n",
    "# perl. to 2\n",
    "# neptune. to 3\n",
    "# smurf. to 4 \n",
    "# guess_passwd. to 5\n",
    "# teardrop. to 6 \n",
    "# portsweep. to 7\n",
    "# imap. to 8 \n",
    "# ipsweep. to 9\n",
    "# land. to 10 \n",
    "# ftp_write. to 11 \n",
    "# back. to 12 \n",
    "# satan. to 13\n",
    "# phf. to 14 \n",
    "# nmap. to 15\n",
    "# multihop. to 16 \n",
    "# warezmaster. to 17\n",
    "# warezclient. to 18\n",
    "# spy. to 19\n",
    "# rootkit. to 20\n",
    "# pod. to 21\n",
    "\n",
    "# normal to 0\n",
    "# dos to 1 (neptune, smurf, land, back)\n",
    "# probe to 2 (ipsweep, postsweep)\n",
    "# r2l to 3 (guess_passwd)\n",
    "# u2r to 4\n",
    "\n",
    "def ModelPrediction(loaded_model):\n",
    "    prediction = {}\n",
    "    prediction[0]  = loaded_model.predict([[184,1,0,1511,2957,0,0,0,3,0,1,2,1,0,1,0,0,0,0,1,1,0,0,10,0,0,1,3,0,100,67,-1]])             # 4\n",
    "    prediction[1]  = loaded_model.predict([[0,1,0,212,1940,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,2,0,0,10,0,0,2,70,0,50,4,0]])                  # 0\n",
    "    prediction[2]  = loaded_model.predict([[79,1,0,281,1301,0,0,0,2,0,1,1,1,0,4,2,0,0,0,1,1,0,0,10,0,0,1,10,0,100,30,1]])               # 4\n",
    "    prediction[3]  = loaded_model.predict([[25,1,0,269,2333,0,0,0,0,0,1,0,1,0,2,1,0,0,0,1,1,0,0,10,0,0,69,2,0,1,0,2]])                  # 4\n",
    "    prediction[4]  = loaded_model.predict([[0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,7,88,0,8,2,0,7,8,0,14,25,3]])                       # 1\n",
    "    prediction[5]  = loaded_model.predict([[0,0,0,1032,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,511,511,0,0,10,0,0,151,6,0,4,0,4]])                # 1\n",
    "    prediction[6]  = loaded_model.predict([[23,1,0,104,276,0,0,0,0,5,0,0,0,0,0,0,0,0,0,1,1,0,0,10,0,0,1,2,0,100,100,5]])                # 3\n",
    "    prediction[7]  = loaded_model.predict([[0,2,0,28,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,3,3,0,0,10,0,0,75,3,0,4,0,6]])                       # 1\n",
    "    prediction[8]  = loaded_model.predict([[1,1,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,2,0,10,5,5,0,174,2,0,2,0,7]])                       # 2\n",
    "    prediction[9]  = loaded_model.predict([[31,1,0,1345,10036,0,0,0,0,0,1,16,0,0,0,0,0,0,0,1,1,0,0,10,0,0,255,1,0,0,0,8]])              # 3\n",
    "    prediction[10] = loaded_model.predict([[0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,10,10,0,0,29,1,10,3,0,9]])                      # 2\n",
    "    prediction[11] = loaded_model.predict([[0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,100,0,10,0,0,1,8,0,100,38,10]])                   # 1\n",
    "    prediction[12] = loaded_model.predict([[26,1,0,116,451,0,0,0,2,0,1,0,0,0,1,0,1,0,1,1,1,0,0,10,0,0,1,1,0,100,0,11]])                 # 3\n",
    "    prediction[13] = loaded_model.predict([[0,1,0,54540,8314,0,0,0,2,0,1,1,0,0,0,0,0,0,0,4,4,0,0,10,0,0,4,4,0,25,0,12]])                # 1\n",
    "    prediction[14] = loaded_model.predict([[0,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,0,1,6,0,150,1,0,3,0,13]])                       # 2\n",
    "    prediction[15] = loaded_model.predict([[0,1,0,51,8127,0,0,0,2,0,1,0,1,0,0,0,1,0,0,1,2,0,0,10,0,100,255,255,0,0,0,14]])              # 3\n",
    "    prediction[16] = loaded_model.predict([[0,1,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,100,0,5,10,0,14,1,7,50,0,15]])                    # 2\n",
    "    prediction[17] = loaded_model.predict([[179,1,0,87,319,0,0,0,1,0,1,0,0,0,1,0,0,0,1,1,1,0,0,10,0,0,255,2,0,0,0,16]])                 # 3\n",
    "    prediction[18] = loaded_model.predict([[0,1,0,36,197,0,0,0,0,0,1,0,0,0,1,0,0,0,1,1,1,0,0,10,0,0,255,1,0,0,0,17]])                   # 3\n",
    "    prediction[19] = loaded_model.predict([[0,1,0,334,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,2,0,0,10,0,0,2,2,0,100,0,18]])                    # 3\n",
    "    prediction[20] = loaded_model.predict([[337,1,0,237,1540,0,0,0,0,0,1,0,0,1,1,1,1,0,0,1,1,0,0,10,0,0,255,47,0,0,0,19]])              # 3\n",
    "    prediction[21] = loaded_model.predict([[21,1,0,89,345,0,0,0,1,0,1,0,0,0,1,0,0,0,0,1,1,0,0,10,0,0,255,1,0,0,0,20]])                  # 4\n",
    "    prediction[22] = loaded_model.predict([[0,0,0,1480,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,4,0,0,10,0,50,2,4,0,100,50,21]])                 # 1\n",
    "\n",
    "    results = [4,0,4,4,1,1,3,1,2,3,2,1,3,1,2,3,2,3,3,3,3,4,1]\n",
    "\n",
    "    # for i in prediction:\n",
    "\n",
    "    #     if prediction[i]==0:\n",
    "    #         print(prediction[i], end=\"  -  \" + \"Normal\")\n",
    "    #     elif prediction[i]==1:\n",
    "    #         print(prediction[i], end=\"  -  \" + \"neptune, smurf, teardrop, land, back\")\n",
    "    #     elif prediction[i]==2:\n",
    "    #         print(prediction[i], end=\"  -  \" + \"portsweep, ipsweep, satan, nmap\")\n",
    "    #     elif prediction[i]==3:\n",
    "    #         print(prediction[i], end=\"  -  \" + \"guess_passwd, imap, ftp_write, phf, multihop, warezmaster, warezclient, spy\")\n",
    "    #     elif prediction[i]==4:\n",
    "    #         print(prediction[i], end=\"  -  \" + \"buffer_overflow, loadmodule, perl, rootkit\")\n",
    "    #     else:\n",
    "    #         print(prediction[i], end=\" - \" + \"No match Found\")\n",
    "    #     print(\"\")\n",
    "\n",
    "    crt=0\n",
    "    wrong=0\n",
    "\n",
    "    for i in prediction:\n",
    "        if prediction[i]==results[i]:\n",
    "            crt = crt + 1\n",
    "        else:\n",
    "            wrong = wrong + 1\n",
    "        # print(prediction[i],\" - \",results[i])\n",
    "    print(\"Correct = \",crt,\"Wrong = \",wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  23 Wrong =  0\n"
     ]
    }
   ],
   "source": [
    "# DTree\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/DecisionTree.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  0 Wrong =  23\n"
     ]
    }
   ],
   "source": [
    "# LinearRegression\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/LinearRegression.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  5 Wrong =  18\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/LogisticRegression.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  22 Wrong =  1\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/RandomForest.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  18 Wrong =  5\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/GradientBoosting.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  23 Wrong =  0\n"
     ]
    }
   ],
   "source": [
    "# Extreme Gradient Boosting\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/XGBoost.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  4 Wrong =  19\n"
     ]
    }
   ],
   "source": [
    "# Navie Bayes\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/NavieBayes.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct =  6 Wrong =  17\n"
     ]
    }
   ],
   "source": [
    "# DeepBN\n",
    "\n",
    "loaded_model = pickle.load(open(\"./ML/DeepBN.pkl\", \"rb\"))\n",
    "ModelPrediction(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "[[9.99021292e-01 2.23590652e-15 7.87096433e-05 3.02314038e-05\n",
      "  8.69209296e-04 1.62115050e-08 3.59030565e-08 2.88429742e-08\n",
      "  4.61271732e-08 3.25763239e-08 1.12649925e-08 1.74436359e-08\n",
      "  3.02527887e-08 2.25824408e-08 2.89796205e-08 2.35564013e-08\n",
      "  3.72830335e-08 3.66521249e-08 5.01564088e-08 2.94495734e-08\n",
      "  3.75347611e-08 3.06924122e-08 2.41515714e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Long Short Term Memory\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained LSTM model\n",
    "loaded_model = load_model('./ML/LongShortTMem.h5')\n",
    "\n",
    "# Preprocess your input data to match the shape of the data used for training the model\n",
    "input_data = np.array([[179,1,0,87,319,0,0,0,1,0,1,0,0,0,1,0,0,0,1,1,1,0,0,10,0,0,255,2,0,0,0,16]])\n",
    "input_data = np.reshape(input_data, (input_data.shape[0], 1, input_data.shape[1]))\n",
    "\n",
    "# Make predictions using the LSTM model\n",
    "prediction = loaded_model.predict(input_data)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 42), found shape=(None, 41)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m input_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m24\u001b[39m,\u001b[39m9\u001b[39m,\u001b[39m206\u001b[39m,\u001b[39m1491\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m17\u001b[39m,\u001b[39m20\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m1.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m1.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m,\u001b[39m0.0\u001b[39m]])\n\u001b[0;32m     19\u001b[0m \u001b[39m# Make a prediction using the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m prediction_data \u001b[39m=\u001b[39m loaded_discriminator\u001b[39m.\u001b[39;49mpredict(input_data)\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(prediction_data)\n",
      "File \u001b[1;32mc:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file59wcl2kn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\abish\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 42), found shape=(None, 41)\n"
     ]
    }
   ],
   "source": [
    "# GAN\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the discriminator, generator model\n",
    "loaded_discriminator = tf.keras.models.load_model('./ML/GAN/discriminator.h5')\n",
    "loaded_generator = tf.keras.models.load_model('./ML/GAN/generator.h5')\n",
    "\n",
    "# Tensorflow Warning Fix\n",
    "@tf.function(input_signature=(tf.TensorSpec(shape=[None], dtype=tf.int32),))\n",
    "def next_collatz(x):\n",
    "    print(\"Tracing with\", x)\n",
    "    return tf.where(x % 2 == 0, x // 2, 3 * x + 1)\n",
    "\n",
    "\n",
    "\n",
    "# Custom input data\n",
    "input_data = np.array([[0,1,24,9,206,1491,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,17,20,0.0,0.0,0.0,0.0,1.0,0.0,0.1,0,255,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]])\n",
    "\n",
    "# Make a prediction using the model\n",
    "prediction_data = loaded_discriminator.predict(input_data)\n",
    "print(prediction_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "727a28ee4c40c57140038d04f8464ce2838cdd9cbed412c77ad124b108b93625"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
